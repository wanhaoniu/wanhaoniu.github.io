<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Wanhao Niu - Personal Homepage</title>
    <style>
        .about-me-container {
            display: flex;
            align-items: flex-start;
        }
        .about-me-text {
            margin-right: 100px;
        }
        img.publication-image {
            width: 300px;
            height: auto;
            margin-right: 10px;
        }
        .publication-entry {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }
        .date {
            font-family: monospace;
            font-size: 16px;
        }
        .document-thumbnails {
            display: flex;
            justify-content: space-between;
            flex-wrap: wrap;
            margin-top: 10px;
            gap: 50px; /* 添加等距间隙 */
        }
        .document-thumbnail {
            text-align: center;        /* 文字和图片居中对齐 */
            width: 20%;                /* 每个缩略图占据容器的 23% 宽度 */
            box-sizing: border-box;    /* 使 padding 和 border 计入总宽度 */
        }
        .document-thumbnail p {
            text-align: flex;
            font-size: 16px;
            margin: 0; /* 移除默认的上下边距 */
            padding-top: 2px; /* 如需微调，可添加上内边距 */
        }
        .document-thumbnail img {
            border: 1px solid #ccc;
            padding: 5px;
            margin-bottom: 0;
            width: 180px;
            height: auto;
        }
        .education-images-container {
            display: flex;
            align-items: flex-start;
        }
        .education-images-container section {
            flex: 1;
        }
        .images-container {
            display: flex;
            flex-direction: column;
            margin-left: 20px;
        }
        .images-container img {
            width: 250px; /* 根据需要调整宽度 */
            margin-bottom: 0; /* 使图片之间的间距更小 */
            margin-right: 50px;
            margin-top: 30px;
        }
        .course-list {
            margin-left: 150px; /* 与日期的宽度保持一致，使得文字对齐 */
            margin-top: 5px;
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <section class="about-me-container">
        <div class="about-me-text">
            <h2>About Me</h2>
            <p>Hello, I'm Wanhao Niu, currently pursuing a Master's degree in Mechanical Engineering at Shanghai Jiao Tong University under the supervision of Prof. Chungang Zhuang, expected to graduate in June 2025. In 2024, I spent five months at Tokyo Institute of Technology under the guidance of Prof. Masaki Yamakita during an exchange program called YSEP. My research focuses on AI-driven model-free object grasping in unstructured environments, and I have extensive experience in robotic grasping and deep learning. I have received the National Scholarship and was recognized for my excellent undergraduate thesis (top 1%). Additionally, I serve as a reviewer for ICRA. I am planning to apply for a PhD program in 2025 to further advance my research in this field.</p>
            <!-- <p>Please find my resume <a href="CV Wanhao Niu.pdf">here</a>; my undergraduate transcript <a href="Undergraduate Transcript Wanhao Niu.pdf">here</a>; and my graduate transcript <a href="Graduate Transcript Wanhao Niu.pdf">here</a>.</p> -->
            <div class="document-thumbnails">
                <div class="document-thumbnail">
                    <a href="CV Wanhao Niu.pdf">
                        <img src="images/cv_thumbnail.jpg" alt="CV" style="width:50px;height: 70px;">
                        <p>Resume</p>
                    </a>
                </div>
                <div class="document-thumbnail">
                    <a href="Undergraduate Transcript Wanhao Niu.pdf">
                        <img src="images/undergraduate_transcript_thumbnail.jpg" alt="Undergraduate Transcript" style="width:50px;height:70px;">
                        <p>Undergraduate Transcript</p>
                    </a>
                </div>
                <div class="document-thumbnail">
                    <a href="Graduate Transcript Wanhao Niu.pdf">
                        <img src="images/graduate_transcript_thumbnail.jpg" alt="Graduate Transcript" style="width:50px;height:70px;">
                        <p>Graduate Transcript</p>
                    </a>
                </div>
                <div class="document-thumbnail">
                    <a href="Research Proposal Wanhao Niu.pdf">
                        <img src="images/research_thumbnail.jpg" alt="Research Proposal" style="width:50px;height:70px;">
                        <p>Research Proposal</p>
                    </a>
                </div>
            </div>
            <p>* The brief research proposal is only on the draft stage.</p>
            <p>If you'd like to get in touch, please email me at <a href="mailto:nwh1093412390@sjtu.edu.cn">nwh1093412390@sjtu.edu.cn</a> or <a href="mailto:wandeneh@gmail.com">wandeneh@gmail.com</a>.</p>
        </div>
        <img src="pic/profile.jpg" alt="Wanhao Niu's Photo" style="width:400px;height:auto;">
    </section>
    <div class="education-images-container">
        <section>
            <h2>Education</h2>
            <ul>
                <li><strong class="date">2018.09 - 2022.07:</strong> <strong>Xi'an Jiao Tong University - Bachelor's degree in Mechanical Engineering</strong> (GPA: <strong>90.19</strong>, Rank: <strong>5/205</strong>)</li>
                <ul class="course-list">
                    <li>Linear Algebra: 98; Advanced Mathematics: 91; Physics: 99; Machine Design: 93; Electrical engineering: 95; Thesis: A+</li>
                </ul>
                <li><strong class="date">2022.09 - 2025.06:</strong> <strong>Shanghai Jiao Tong University - Master's degree in Mechanical Engineering</strong> (GPA: <strong>3.72</strong>)</li>
                <ul class="course-list">
                    <li>Digital Signal Processing: A+; Matrix Theory: A-; Computer Graphics: A; Modern Control Theory: A-; Intelligent Control Technology: A</li>
                </ul>
                <li><strong class="date">2024.04 - 2024.09:</strong> <strong>Tokyo Institute of Technology - YSEP Exchange Student</strong> (Research: Model-Free Object Grasping Technology Driven by Artificial Intelligence)</li>
            </ul>
        </section>
        <div class="images-container">
            <!-- 在这里添加您的三张长条形图片 -->
            <img src="images/Uni.png" alt="Image 1">
        </div>
    </div>
    <section>
        <h2>Languages</h2>
        <ul>
            <li>Mandarin Chinese (Native)</li>
            <li>English (Fluent - IELTS 6.5)</li>
        </ul>
    </section>
    <section>
        <h2>Research Interests</h2>
        <ul>
            <li>Model-Free Object Grasping Technology; Robotic Grasping; Deep Learning; Graph Convolutional Networks</li>
        </ul>
    </section>
    <section>
        <h2>Publications</h2>
        <h3>Journal Papers</h3>
        <div class="publication-entry">
            <img src="pic/EAAI.jpg" alt="Journal Paper 1 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1016/j.engappai.2024.109320"><strong>Niu W.</strong>, Zhu Z., Wang H., Zhuang C. - Customizable 6 Degrees of Freedom Grasping Dataset and an Interactive Training Method for GCN (Engineering Application of Artificial Intelligence)</a>  <a href="https://github.com/cgzhuang/CGra-D">Code</a>
                <p>We introduce an innovative method for generating robotic grasping datasets in simulated environments without manual annotations—utilizing customizable gripper movements and detailed evaluation metrics—to enhance dataset diversity and applicability; additionally, we present an end-to-end grasp prediction network leveraging advanced graph convolution techniques and a novel interactive training method that together improve model performance and training efficiency in robotic grasping applications.</p>
            </div>
        </div>
        <div class="publication-entry">
            <img src="pic/IEEETCDS.jpg" alt="Journal Paper 2 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1109/TCDS.2024.3403900"><strong>Niu W.</strong>, Wang H., Zhuang C. - Adaptive Multiview Graph Convolutional Network for 3D Point Cloud Classification and Segmentation (IEEE Transactions on Cognitive and Developmental Systems)</a> <a href="https://github.com/cgzhuang/AM-GCN">Code</a>
                <p>We propose an adaptive multiview graph convolutional network (AM-GCN) that integrates global geometric features and local features from multiple view projections of point clouds to address the limitation of existing methods that overlook long-distance geometric relationships, thereby enhancing point cloud classification and segmentation accuracy with competitive performance across multiple datasets.</p>
            </div>
        </div>
        <div class="publication-entry">
            <img src="pic/ASME.jpg" alt="Journal Paper 3 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1115/1.4066281">Zhuang C., <strong>Niu W.</strong>, Wang H. - Sparse Convolution-Based 6D Pose Estimation for Robotic Bin-Picking With Point Clouds (Journal of Mechanisms and Robotics)</a> <a href="https://github.com/cgzhuang/Sparse-convolution-based-6D-pose-estimation-for-robotic-bin-picking-with-point-clouds">Code</a>
                <p>We introduce a novel two-stage neural network that processes point clouds to predict 6D object poses for robotic bin-picking tasks, effectively overcoming challenges of occlusion and random stacking, outperforming baseline methods in both segmentation accuracy and pose refinement, and demonstrating efficacy in real-world industrial applications.</p>
            </div>
        </div>
        <div class="publication-entry">
            <img src="pic/RCIM.jpg" alt="Journal Paper 4 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1016/j.rcim.2024.102879">Zhuang C., Wang H., <strong>Niu W.</strong>, Han D. - A Parallel Graph Network for Generating 7-DoF Model-free Grasps in Unstructured Scenes Using Point Cloud (Robotics and Computer-Integrated Manufacturing)</a>
                <p>We propose a parallelized graph-based pipeline for 7-DoF grasp pose generation from point clouds that simultaneously performs feature embedding and grasp location focusing in two branches using a positional attention-based graph convolution operator, resulting in improved grasp predictions that outperform benchmarks on the GraspNet-1Billion dataset and achieve high success rates in real-world robotic grasping of unknown objects.</p>
            </div>
        </div>
        <h3>Conference Papers</h3>
        <div class="publication-entry">
            <img src="pic/ICMRE.jpg" alt="Conference Paper 1 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1109/ICMRE56789.2023.10106576"><strong>Niu W.</strong>, Wang H., Zhuang C. - Detection for Tiny Screw and Screw Hole by Semantic Segmentation Model (ICMRE 2023)</a>
                <p>We propose a method combining semantic segmentation models with post-processing to improve the detection of screws and screw holes on mobile phone PCBs, achieving 99.7% accuracy even in vibrating conditions, thereby enhancing the stability and efficiency of automatic assembly and disassembly on production lines.</p>
            </div>
        </div>
        <div class="publication-entry">
            <img src="pic/IROS.jpg" alt="Conference Paper 2 Image" class="publication-image">
            <div>
                <a href="https://doi.org/10.1109/IROS55552.2023.10341549">Wang H., <strong>Niu W.</strong>, Zhuang C. - GraNet: A Multi-level Graph Network for 6-DoF Grasp Generation in Cluttered Scenes (IROS 2023)</a> <a href="https://github.com/wanhaoniu/GraNet">Code</a>
                <p>We propose GraNet, a graph-based grasp pose generation framework that translates point cloud scenes into multi-level graphs to enhance feature embedding and improve 6-DoF object-agnostic grasping in unstructured environments, achieving state-of-the-art performance and higher grasp success rates, especially on unseen objects.</p>
            </div>
        </div>
    </section>
    <section>
        <h2>Honors & Awards</h2>
        <ul>
            <li>JASSO Scholarship, Tokyo Institute of Technology (April 2024)</li>
            <li>Graduate National Scholarship, Shanghai Jiao Tong University (September 2023)</li>
            <li>Excellent Undergraduate Thesis (Top 1%), Xi'an Jiao Tong University (July 2022)</li>
            <li>Outstanding Graduate Student of Shaanxi Province, Xi'an Jiao Tong University (July 2022)</li>
            <li>First Prize: Challenge Cup National Competition, Xi'an Jiao Tong University (April 2022)</li>
            <li>Shangyin Elite Student Scholarship, Xi'an Jiao Tong University (September 2021)</li>
        </ul>
    </section>
    <section>
        <h2>Professional Skills</h2>
        <ul>
            <li>Hardware: UR Robot Platform, PhotoNeo Industrial Camera, Signal Generator</li>
            <li>Software: VSCode, MATLAB, AutoCAD, SolidWorks, COMSOL</li>
            <li>Programming Languages: Python (Proficient), MATLAB (Basic), C++ (Basic)</li>
            <li>Frameworks: PyTorch (Proficient), OpenCV (Proficient), PyBullet (Proficient), TensorFlow (Basic), Issac Lab (Basic)</li>
        </ul>
    </section>
    <section>
        <h2>Hobbies & Interests</h2>
        <ul>
            <li>City Walk; Table Tennis; Photography; Traveling and Cultural Exchange</li>
        </ul>
    </section>    
</body>
</html>
